{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:44:41.684176Z",
     "start_time": "2024-01-23T20:44:41.651925900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PSAP.Problem import decimal_to_time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/TABU/ML-Results/ML151-200x10-redo-c.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# THE SAME AS THE DL MODEL\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_ml \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresults/TABU/ML-Results/ML151-200x10-redo-c.xlsx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df_ml \u001B[38;5;241m=\u001B[39m df_ml\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber of movements\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmovements_reached-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedian delay\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedian_delay-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage delay\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage_delay-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj_val\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj_val-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msolution_found\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid_solution-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted_delay\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted_delay-ML\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtabu_list_size\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtabu_list_size-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber_of_tweaks\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber_of_tweaks-ML\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maffected_movements\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maffected_movements-ML\u001B[39m\u001B[38;5;124m'\u001B[39m,})\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# add 100 to the instance number\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001B[0m, in \u001B[0;36mread_excel\u001B[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[0;32m    503\u001B[0m     should_close \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m     io \u001B[38;5;241m=\u001B[39m \u001B[43mExcelFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;241m!=\u001B[39m io\u001B[38;5;241m.\u001B[39mengine:\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    512\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    514\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001B[0m, in \u001B[0;36mExcelFile.__init__\u001B[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1563\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[43minspect_excel_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1566\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1567\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1568\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExcel file format cannot be determined, you must specify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1569\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man engine manually.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1570\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001B[0m, in \u001B[0;36minspect_excel_format\u001B[1;34m(content_or_path, storage_options)\u001B[0m\n\u001B[0;32m   1416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m   1417\u001B[0m     content_or_path \u001B[38;5;241m=\u001B[39m BytesIO(content_or_path)\n\u001B[1;32m-> 1419\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1421\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[0;32m   1422\u001B[0m     stream \u001B[38;5;241m=\u001B[39m handle\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m   1423\u001B[0m     stream\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\common.py:872\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    864\u001B[0m             handle,\n\u001B[0;32m    865\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    868\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m         )\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    873\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'results/TABU/ML-Results/ML151-200x10-redo-c.xlsx'"
     ]
    }
   ],
   "source": [
    "# THE SAME AS THE MH MODEL\n",
    "df_ml = pd.read_excel('../../results/TABU/ML-Results/ML151-200x10-redo-c.xlsx')\n",
    "df_ml = df_ml.rename(columns={'number of movements': 'movements_reached-ML', 'median delay': 'median_delay-ML', 'average delay': 'average_delay-ML', 'obj_val': 'obj_val-ML', 'solution_found': 'valid_solution-ML', 'predicted_delay': 'predicted_delay-ML','tabu_list_size': 'tabu_list_size-ML', 'number_of_tweaks': 'number_of_tweaks-ML', 'affected_movements': 'affected_movements-ML',})\n",
    "\n",
    "# add 100 to the instance number\n",
    "df_ml['instance'] = df_ml['instance'] + 100\n",
    "print(df_ml.head(20))\n",
    "\n",
    "df_tabu = pd.read_excel('results/TABU/output_1000e_200_ctd1.xlsx')\n",
    "\n",
    "df_tabu = df_tabu.rename(columns={'number of movements': 'movements_reached-TABU', 'median delay': 'median_delay-TABU', 'average delay': 'average_delay-TABU', 'obj_val': 'obj_val-TABU', 'solution_found': 'valid_solution-TABU', 'predicted_delay': 'predicted_delay-TABU', 'tabu_list_size': 'tabu_list_size-TABU', 'number_of_tweaks': 'number_of_tweaks-TABU', 'affected_movements': 'affected_movements-TABU',})\n",
    "\n",
    "df_tabu = df_tabu[1500:3000]\n",
    "\n",
    "# drop the rows that are not needed\n",
    "# keep the ones that are divisible by 3\n",
    "df_tabu = df_tabu[df_tabu.index % 3 == 0]\n",
    "\n",
    "\n",
    "# load in the instance data\n",
    "df_instances = pd.read_excel('results/instanceData_200.xlsx')\n",
    "df_instances = df_instances[['instance', 'number_of_movements']] \n",
    "# only keep the instace 151-200\n",
    "df_instances = df_instances.sort_values(by=['instance'])\n",
    "df_instances = df_instances[150:200]\n",
    "\n",
    "# merge the instances with the SA&ML data\n",
    "df_ml = pd.merge(df_ml, df_instances, on='instance')\n",
    "df_tabu = pd.merge(df_tabu, df_instances, on='instance')\n",
    "\n",
    "# to excel for checking\n",
    "df_ml.to_excel('results/TABU/ML-Results/check.xlsx')\n",
    "df_tabu.to_excel('results/TABU/check.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:44:56.162367500Z",
     "start_time": "2024-01-23T20:44:53.135401600Z"
    }
   },
   "id": "803a2c8ce9dedf17",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML valid solutions:  100\n",
      "TABU valid solutions:  83\n",
      "ML average movements reached:  0.7624987157765534\n",
      "TABU average movements reached:  0.7492172379286461\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# calculate the amouunt of valid solutions\n",
    "print('ML valid solutions: ', df_ml['valid_solution-ML'].sum())\n",
    "print('TABU valid solutions: ', df_tabu['valid_solution-TABU'].sum())\n",
    "\n",
    "# calculate the average delay\n",
    "df_results = pd.DataFrame()\n",
    "df_results['avg_movements_reached-ML'] = df_ml['movements_reached-ML']/df_ml['number_of_movements']\n",
    "df_results['avg_movements_reached-TABU'] = df_tabu['movements_reached-TABU']/df_tabu['number_of_movements']\n",
    "average_ML = df_results['avg_movements_reached-ML'].sum() / len(df_results)\n",
    "average_TABU = df_results['avg_movements_reached-TABU'].sum() / len(df_results)\n",
    "print('ML average movements reached: ', average_ML)\n",
    "print('TABU average movements reached: ', average_TABU)\n",
    "\n",
    "print(len(df_ml))\n",
    "print(len(df_tabu))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:05:38.216569300Z",
     "start_time": "2024-01-08T10:05:38.196939800Z"
    }
   },
   "id": "9ada2d2eccd150db",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "495    0\n",
      "496    0\n",
      "497    0\n",
      "498    0\n",
      "499    0\n",
      "Name: valid_solution-ML, Length: 500, dtype: int64\n",
      "ML valid solutions:  64\n",
      "TABU valid solutions:  64\n",
      "ML average delay:  0:37\n",
      "TABU average delay:  0:37\n",
      "ML average median delay:  0:27\n",
      "TABU average median delay:  0:29\n",
      "ML average obj val:  63.20703125000067\n",
      "TABU average obj val:  60.403645833334004\n",
      "ML standard deviation:  0:21\n",
      "TABU standard deviation:  0:20\n"
     ]
    }
   ],
   "source": [
    "# add the solved column from ml to tabu\n",
    "df_tabu['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "print(df_tabu['valid_solution-ML'])\n",
    "df_ml['valid_solution-TABU'] = df_tabu['valid_solution-TABU']\n",
    "\n",
    "# calculate the average on the solved instances\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_tabu_solved = df_tabu[df_tabu['valid_solution-TABU'] == 1]\n",
    "\n",
    "# now only keep if the instance is solved in both ML and TABU\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-TABU'] == 1]\n",
    "df_tabu_solved = df_tabu_solved[df_tabu_solved['valid_solution-ML'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions\n",
    "print('ML valid solutions: ', df_ml_solved['valid_solution-ML'].sum())\n",
    "print('TABU valid solutions: ', df_tabu_solved['valid_solution-TABU'].sum())\n",
    "\n",
    "# calculate the average wait time\n",
    "avg_delay_ML = df_ml_solved['average_delay-ML'].sum() / len(df_ml_solved)\n",
    "avg_delay_TABU = df_tabu_solved['average_delay-TABU'].sum() / len(df_tabu_solved)\n",
    "print('ML average delay: ', decimal_to_time(avg_delay_ML))\n",
    "print('TABU average delay: ', decimal_to_time(avg_delay_TABU))\n",
    "\n",
    "# calculate the average median delay for ML and TABU\n",
    "avg_median_ML = df_ml_solved['median_delay-ML'].sum() / len(df_ml_solved)\n",
    "avg_median_TABU = df_tabu_solved['median_delay-TABU'].sum() / len(df_tabu_solved)\n",
    "print('ML average median delay: ', decimal_to_time(avg_median_ML))\n",
    "print('TABU average median delay: ', decimal_to_time(avg_median_TABU))\n",
    "\n",
    "# calculate the average obj val for ML and TABU\n",
    "avg_obj_ML = df_ml_solved['obj_val-ML'].sum() / len(df_ml_solved)\n",
    "avg_obj_TABU = df_tabu_solved['obj_val-TABU'].sum() / len(df_tabu_solved)\n",
    "print('ML average obj val: ', avg_obj_ML)\n",
    "print('TABU average obj val: ', avg_obj_TABU)\n",
    "\n",
    "# calcute the standard deviation for ML and TABU on the average delay\n",
    "std_ML = df_ml_solved['average_delay-ML'].std()\n",
    "std_TABU = df_tabu_solved['average_delay-TABU'].std()\n",
    "print('ML standard deviation: ', decimal_to_time(std_ML))\n",
    "print('TABU standard deviation: ', decimal_to_time(std_TABU))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:05:40.026464900Z",
     "start_time": "2024-01-08T10:05:40.003601600Z"
    }
   },
   "id": "5ffec1484313757a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML valid solutions:  64\n",
      "TABU valid solutions:  64\n",
      "avg delay difference:  0.0004709102208134159\n",
      "avg delay difference std:  0.44180371792002776\n",
      "median delay difference:  -0.026041666666666786\n",
      "median delay difference std:  0.4685607348652845\n",
      "obj val difference:  2.803385416666666\n",
      "obj val difference std:  54.166158661003294\n"
     ]
    }
   ],
   "source": [
    "# compare on instances that both ML and TABU solved\n",
    "df_tabu['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-TABU'] = df_tabu['valid_solution-TABU']\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_tabu_solved = df_tabu[df_tabu['valid_solution-TABU'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-TABU'] == 1]\n",
    "df_tabu_solved = df_tabu_solved[df_tabu_solved['valid_solution-ML'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print('ML valid solutions: ', df_ml_solved['valid_solution-ML'].sum())\n",
    "print('TABU valid solutions: ', df_tabu_solved['valid_solution-TABU'].sum())\n",
    "\n",
    "obj_val_diff = df_ml_solved['obj_val-ML'] - df_tabu_solved['obj_val-TABU']\n",
    "avg_diff = df_ml_solved['average_delay-ML'] - df_tabu_solved['average_delay-TABU']\n",
    "median_diff = df_ml_solved['median_delay-ML'] - df_tabu_solved['median_delay-TABU']\n",
    "print('avg delay difference: ', avg_diff.mean())\n",
    "print('avg delay difference std: ', avg_diff.std())\n",
    "print('median delay difference: ', median_diff.mean())\n",
    "print('median delay difference std: ', median_diff.std())\n",
    "print('obj val difference: ', obj_val_diff.mean())\n",
    "print('obj val difference std: ', obj_val_diff.std())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:05:42.367729900Z",
     "start_time": "2024-01-08T10:05:42.343927900Z"
    }
   },
   "id": "a06420da402172bc",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instance', 'movements_reached-TABU', 'median_delay-TABU',\n",
      "       'average_delay-TABU', 'obj_val-TABU', 'tabu_list_size-TABU',\n",
      "       'number_of_tweaks-TABU', 'affected_movements-TABU', 'epochs',\n",
      "       'time_interval', 'vessel_time_window', 'valid_solution-TABU'],\n",
      "      dtype='object')\n",
      "Index(['instance', 'movements_reached-ML', 'median_delay-ML',\n",
      "       'average_delay-ML', 'obj_val-ML', 'tabu_list_size-ML',\n",
      "       'number_of_tweaks-ML', 'affected_movements-ML', 'epochs',\n",
      "       'time_interval', 'vessel_time_window', 'valid_solution-ML',\n",
      "       'predicted_delay-ML'],\n",
      "      dtype='object')\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# now for the reasonable comparison\n",
    "import pandas as pd\n",
    "df_tabu = pd.read_excel('results/TABU/output_151-200ex10-REAS.xlsx')\n",
    "df_tabu = df_tabu.rename(columns={'number of movements': 'movements_reached-TABU', 'median delay': 'median_delay-TABU', 'average delay': 'average_delay-TABU', 'obj_val': 'obj_val-TABU', 'solution_found': 'valid_solution-TABU', 'predicted_delay': 'predicted_delay-TABU', 'tabu_list_size': 'tabu_list_size-TABU', 'number_of_tweaks': 'number_of_tweaks-TABU', 'affected_movements': 'affected_movements-TABU',})\n",
    "\n",
    "print(df_tabu.columns)\n",
    "# load in the ml data\n",
    "df_ml1 = pd.read_excel('results/TABU/ML-Results/ML151-200x10-REAS-redo-c.xlsx')\n",
    "# df_ml2 = pd.read_excel('results/TABU/ML-Results/ML151-200x10-REAS-redo-c_ctd1.xlsx')\n",
    "\n",
    "df_ml = pd.concat([df_ml1, df_ml2])\n",
    "df_ml = df_ml.rename(columns={'number of movements': 'movements_reached-ML', 'median delay': 'median_delay-ML', 'average delay': 'average_delay-ML', 'obj_val': 'obj_val-ML', 'solution_found': 'valid_solution-ML', 'predicted_delay': 'predicted_delay-ML','tabu_list_size': 'tabu_list_size-ML', 'number_of_tweaks': 'number_of_tweaks-ML', 'affected_movements': 'affected_movements-ML',})\n",
    "print(df_ml.columns)\n",
    "print(len(df_ml))\n",
    "print(len(df_tabu))\n",
    "\n",
    "# to excel for checking\n",
    "df_ml.to_excel('results/TABU/ML-Results/check.xlsx')\n",
    "df_tabu.to_excel('results/TABU/check.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T16:32:08.192319300Z",
     "start_time": "2024-01-10T16:32:07.487061200Z"
    }
   },
   "id": "b77aa31c79c8de37",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df_ml.index.is_unique)\n",
    "\n",
    "# drop the index that is not unique\n",
    "df_ml = df_ml.reset_index(drop=True)\n",
    "print(df_ml.index.is_unique)\n",
    "df_tabu.to_excel('results/TABU/check.xlsx')\n",
    "print(df_ml.index.is_unique)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T16:32:14.266705800Z",
     "start_time": "2024-01-10T16:32:14.104627900Z"
    }
   },
   "id": "e3fed46bd59e0286",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML valid solutions:  49\n",
      "TABU valid solutions:  49\n",
      "avg delay difference:  0.14764612737325505\n",
      "avg delay difference std:  0.4348458318046567\n",
      "median delay difference:  0.09693877551020387\n",
      "median delay difference std:  0.44951972144697444\n",
      "obj val difference:  2.0238095238095974\n",
      "obj val difference std:  56.50450397895224\n"
     ]
    }
   ],
   "source": [
    "# compare on instances that both ML and TABU solved\n",
    "df_tabu['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-TABU'] = df_tabu['valid_solution-TABU']\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_tabu_solved = df_tabu[df_tabu['valid_solution-TABU'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-TABU'] == 1]\n",
    "df_tabu_solved = df_tabu_solved[df_tabu_solved['valid_solution-ML'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print('ML valid solutions: ', df_ml_solved['valid_solution-ML'].sum())\n",
    "print('TABU valid solutions: ', df_tabu_solved['valid_solution-TABU'].sum())\n",
    "\n",
    "obj_val_diff = df_ml_solved['obj_val-ML'] - df_tabu_solved['obj_val-TABU']\n",
    "avg_diff = df_ml_solved['average_delay-ML'] - df_tabu_solved['average_delay-TABU']\n",
    "median_diff = df_ml_solved['median_delay-ML'] - df_tabu_solved['median_delay-TABU']\n",
    "print('avg delay difference: ', avg_diff.mean())\n",
    "print('avg delay difference std: ', avg_diff.std())\n",
    "print('median delay difference: ', median_diff.mean())\n",
    "print('median delay difference std: ', median_diff.std())\n",
    "print('obj val difference: ', obj_val_diff.mean())\n",
    "print('obj val difference std: ', obj_val_diff.std())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T16:32:20.183368400Z",
     "start_time": "2024-01-10T16:32:20.170807Z"
    }
   },
   "id": "705acbc0a4b963c6",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# THE COMPLETELY RANDOM MODEL\n",
    "df_ml = pd.read_excel('results/TABU/ML-Results/ML151-200x10-UNREAS-redo-c.xlsx')\n",
    "\n",
    "df_ml = df_ml.rename(columns={'number of movements': 'movements_reached-ML', 'median delay': 'median_delay-ML', 'average delay': 'average_delay-ML', 'obj_val': 'obj_val-ML', 'solution_found': 'valid_solution-ML', 'predicted_delay': 'predicted_delay-ML','tabu_list_size': 'tabu_list_size-ML', 'number_of_tweaks': 'number_of_tweaks-ML', 'affected_movements': 'affected_movements-ML',})\n",
    "\n",
    "df_tabu = pd.read_excel('results/TABU/output_151-200ex10-UNREAS.xlsx')\n",
    "df_tabu = df_tabu.rename(columns={'number of movements': 'movements_reached-TABU', 'median delay': 'median_delay-TABU', 'average delay': 'average_delay-TABU', 'obj_val': 'obj_val-TABU', 'solution_found': 'valid_solution-TABU', 'predicted_delay': 'predicted_delay-TABU', 'tabu_list_size': 'tabu_list_size-TABU', 'number_of_tweaks': 'number_of_tweaks-TABU', 'affected_movements': 'affected_movements-TABU',})\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T06:02:23.655699300Z",
     "start_time": "2024-01-08T06:02:23.505229900Z"
    }
   },
   "id": "a0b7b96844a7e9b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML valid solutions:  12\n",
      "TABU valid solutions:  12\n",
      "avg delay difference:  -0.11883090248770072\n",
      "avg delay difference std:  0.34525206241079476\n",
      "median delay difference:  -0.138888888888889\n",
      "median delay difference std:  0.3761905903519652\n",
      "obj val difference:  -11.770833333333336\n",
      "obj val difference std:  30.076777280248248\n"
     ]
    }
   ],
   "source": [
    "# compare on instances that both ML and TABU solved\n",
    "df_tabu['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-TABU'] = df_tabu['valid_solution-TABU']\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_tabu_solved = df_tabu[df_tabu['valid_solution-TABU'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-TABU'] == 1]\n",
    "df_tabu_solved = df_tabu_solved[df_tabu_solved['valid_solution-ML'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print('ML valid solutions: ', df_ml_solved['valid_solution-ML'].sum())\n",
    "print('TABU valid solutions: ', df_tabu_solved['valid_solution-TABU'].sum())\n",
    "\n",
    "obj_val_diff = df_ml_solved['obj_val-ML'] - df_tabu_solved['obj_val-TABU']\n",
    "avg_diff = df_ml_solved['average_delay-ML'] - df_tabu_solved['average_delay-TABU']\n",
    "median_diff = df_ml_solved['median_delay-ML'] - df_tabu_solved['median_delay-TABU']\n",
    "print('avg delay difference: ', avg_diff.mean())\n",
    "print('avg delay difference std: ', avg_diff.std())\n",
    "print('median delay difference: ', median_diff.mean())\n",
    "print('median delay difference std: ', median_diff.std())\n",
    "print('obj val difference: ', obj_val_diff.mean())\n",
    "print('obj val difference std: ', obj_val_diff.std())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T06:02:25.315468400Z",
     "start_time": "2024-01-08T06:02:25.305003500Z"
    }
   },
   "id": "42307d6d82f511d3",
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
