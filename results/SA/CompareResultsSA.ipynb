{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PSAP.Problem import decimal_to_time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:23:25.268973Z",
     "start_time": "2024-01-08T05:23:25.258889300Z"
    }
   },
   "id": "1b774f1140762b6b",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load in ML data\n",
    "df_ml = pd.read_excel('results/SA/ML-Results/ML_151-200ex10-001_099.xlsx')\n",
    "df_ml = df_ml[['instance', 'number_of_movements_reached', 'median_delay', 'average_delay','obj_val', 't0', 'alpha', 'predicted_delay', 'valid_solution']]\n",
    "df_ml = df_ml.rename(columns={'number_of_movements_reached': 'movements_reached-ML', 'median_delay': 'median_delay-ML', 'average_delay': 'average_delay-ML', 'obj_val': 'obj_val-ML', 't0': 't0-ML', 'alpha': 'alpha-ML', 'valid_solution': 'valid_solution-ML', 'predicted_delay': 'predicted_delay-ML'})\n",
    "\n",
    "# load in random data\n",
    "df_sa = pd.read_excel('results/SA/ML-Results/output_150-200ex10-001-099.xlsx')\n",
    "df_sa = df_sa[['instance', 'obj_val', 'alpha', 't0', 'median delay', 'average delay', 'number of movements', 'valid_solution']]\n",
    "df_sa = df_sa.rename(columns={'median delay': 'median_delay-SA', 'average delay': 'average_delay-SA', 'number of movements': 'movements_reached-SA', 'obj_val': 'obj_val-SA', 't0': 't0-SA', 'alpha': 'alpha-SA', 'valid_solution': 'valid_solution-SA'})\n",
    "# sort the dataframes on instance\n",
    "df_sa = df_sa.sort_values(by=['instance'])\n",
    "df_ml = df_ml.sort_values(by=['instance'])\n",
    "\n",
    "\n",
    "# load in the instance data\n",
    "df_instances = pd.read_excel('results/instanceData_200.xlsx')\n",
    "df_instances = df_instances[['instance', 'number_of_movements']] \n",
    "# only keep the instace 151-200\n",
    "df_instances = df_instances.sort_values(by=['instance'])\n",
    "df_instances = df_instances[150:200]\n",
    "\n",
    "# merge the instances with the SA&ML data\n",
    "df_ml = pd.merge(df_ml, df_instances, on='instance')\n",
    "df_sa = pd.merge(df_sa, df_instances, on='instance')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:23:30.614315900Z",
     "start_time": "2024-01-08T05:23:30.394019900Z"
    }
   },
   "id": "671d4aed5a1499f8",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  392\n",
      "valid solutions ML:  408\n",
      "average movements reached SA:  0.9631006224084153\n",
      "average movements reached ML:  0.9697388404354822\n"
     ]
    }
   ],
   "source": [
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml['valid_solution-ML'].sum())\n",
    "\n",
    "# calculate the average movement reached for SA and ML\n",
    "df_results = pd.DataFrame()\n",
    "df_results['avg_movements_reached-ML'] = df_ml['movements_reached-ML']/df_ml['number_of_movements']\n",
    "df_results['avg_movements_reached-SA'] = df_sa['movements_reached-SA']/df_sa['number_of_movements']\n",
    "average_SA = df_results['avg_movements_reached-SA'].sum() / len(df_results)\n",
    "average_ML = df_results['avg_movements_reached-ML'].sum() / len(df_results)\n",
    "print(\"average movements reached SA: \", average_SA)\n",
    "print(\"average movements reached ML: \", average_ML)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:23:35.425717500Z",
     "start_time": "2024-01-08T05:23:35.396796400Z"
    }
   },
   "id": "14f404f09b37a909",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average delay SA:  0:51\n",
      "average delay ML:  0:48\n",
      "average of median delay SA:  0:42\n",
      "average median delay ML:  0:39\n",
      "average objval SA:  87.24916666666667\n",
      "average objval ML:  83.15333333333334\n"
     ]
    }
   ],
   "source": [
    "# calculate the average delay for SA and ML\n",
    "avg_delay_SA = df_sa['average_delay-SA'].sum() / len(df_sa)\n",
    "avg_delay_ML = df_ml['average_delay-ML'].sum() / len(df_ml)\n",
    "print(\"average delay SA: \", decimal_to_time(avg_delay_SA))\n",
    "print(\"average delay ML: \", decimal_to_time(avg_delay_ML))\n",
    "\n",
    "# calculate average median delay for SA and ML\n",
    "median_delay_SA = df_sa['median_delay-SA'].sum() / len(df_sa)\n",
    "median_delay_ML = df_ml['median_delay-ML'].sum() / len(df_ml)\n",
    "print(\"average of median delay SA: \", decimal_to_time(median_delay_SA))\n",
    "print(\"average median delay ML: \", decimal_to_time(median_delay_ML))\n",
    "\n",
    "# calculate average objval for SA and ML\n",
    "objval_SA = df_sa['obj_val-SA'].sum() / len(df_sa)\n",
    "objval_ML = df_ml['obj_val-ML'].sum() / len(df_ml)\n",
    "print(\"average objval SA: \", objval_SA) # i made a mistake in how the objval is saved: the ML saves the objval of the failed solution, while the SA saves the objval of the last valid solution\n",
    "print(\"average objval ML: \", objval_ML)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:17:08.238972700Z",
     "start_time": "2024-01-07T17:17:08.219093Z"
    }
   },
   "id": "d7590d07220bfd1c",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  382\n",
      "valid solutions ML:  382\n",
      "average and stddev: ( 0.056340157563702455 0.2971838602373348 )\n",
      "median and stddev: ( 0.051047120418848096 0.35574175476373787 )\n"
     ]
    }
   ],
   "source": [
    "df_sa['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-SA'] = df_sa['valid_solution-SA']\n",
    "\n",
    "# now only look at the instances that are solved by both SA and ML\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_sa_solved = df_sa[df_sa['valid_solution-SA'] == 1]\n",
    "\n",
    "df_sa_solved = df_sa_solved[df_sa_solved['valid_solution-ML'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-SA'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa_solved['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml_solved['valid_solution-ML'].sum())\n",
    "\n",
    "\n",
    "\n",
    "# calculate the differnce between the objval of SA and ML\n",
    "objval_diff = df_sa_solved['obj_val-SA'] - df_ml_solved['obj_val-ML']\n",
    "avg_diff = df_sa_solved['average_delay-SA'] - df_ml_solved['average_delay-ML']\n",
    "median_diff = df_sa_solved['median_delay-SA'] - df_ml_solved['median_delay-ML']\n",
    "print(\"average and stddev: (\", avg_diff.mean(), avg_diff.std(), \")\")\n",
    "print(\"median and stddev: (\", median_diff.mean(), median_diff.std(), \")\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:26:17.425357200Z",
     "start_time": "2024-01-08T05:26:17.402778700Z"
    }
   },
   "id": "a545153b87479e4f",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# now we do the same for other parameter ranges first, the reasonable range\n",
    "df_ml = pd.read_excel('results/SA/ML-Results/ML_151-200ex10-020_099.xlsx')\n",
    "df_ml = df_ml[['instance', 'number_of_movements_reached', 'median_delay', 'average_delay','obj_val', 't0', 'alpha', 'predicted_delay', 'valid_solution']]\n",
    "df_ml = df_ml.rename(columns={'number_of_movements_reached': 'movements_reached-ML', 'median_delay': 'median_delay-ML', 'average_delay': 'average_delay-ML', 'obj_val': 'obj_val-ML', 't0': 't0-ML', 'alpha': 'alpha-ML', 'valid_solution': 'valid_solution-ML', 'predicted_delay': 'predicted_delay-ML'})\n",
    "\n",
    "# load in random data\n",
    "df_sa = pd.read_excel('results/SA/ML-Results/output_151-200ex10-020-099.xlsx')\n",
    "df_sa = df_sa[['instance', 'obj_val', 'alpha', 't0', 'median delay', 'average delay', 'number of movements', 'valid_solution']]\n",
    "df_sa = df_sa.rename(columns={'median delay': 'median_delay-SA', 'average delay': 'average_delay-SA', 'number of movements': 'movements_reached-SA', 'obj_val': 'obj_val-SA', 't0': 't0-SA', 'alpha': 'alpha-SA', 'valid_solution': 'valid_solution-SA'})\n",
    "\n",
    "# sort the dataframes on instance\n",
    "df_sa = df_sa.sort_values(by=['instance'])\n",
    "df_ml = df_ml.sort_values(by=['instance'])\n",
    "\n",
    "# load in the instance data\n",
    "df_instances = pd.read_excel('results/instanceData_200.xlsx')\n",
    "df_instances = df_instances[['instance', 'number_of_movements']]\n",
    "# only keep the instace 151-200\n",
    "df_instances = df_instances.sort_values(by=['instance'])\n",
    "df_instances = df_instances[150:200]\n",
    "\n",
    "# merge the instances with the SA&ML data\n",
    "df_ml = pd.merge(df_ml, df_instances, on='instance')\n",
    "df_sa = pd.merge(df_sa, df_instances, on='instance')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:28:06.756047Z",
     "start_time": "2024-01-08T05:28:06.554944400Z"
    }
   },
   "id": "6c1e7da0dd155d6b",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  407\n",
      "valid solutions ML:  401\n"
     ]
    }
   ],
   "source": [
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml['valid_solution-ML'].sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:17:08.484089800Z",
     "start_time": "2024-01-07T17:17:08.468178100Z"
    }
   },
   "id": "73b6d08912c7c66",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average delay SA:  0:49\n",
      "average delay ML:  0:48\n",
      "average of median delay SA:  0:40\n",
      "average median delay ML:  0:40\n",
      "average objval SA:  85.83916666666667\n",
      "average objval ML:  84.1925\n"
     ]
    }
   ],
   "source": [
    "# calculate the average delay for SA and ML\n",
    "avg_delay_SA = df_sa['average_delay-SA'].sum() / len(df_sa)\n",
    "avg_delay_ML = df_ml['average_delay-ML'].sum() / len(df_ml)\n",
    "print(\"average delay SA: \", decimal_to_time(avg_delay_SA))\n",
    "print(\"average delay ML: \", decimal_to_time(avg_delay_ML))\n",
    "\n",
    "# calculate average median delay for SA and ML\n",
    "median_delay_SA = df_sa['median_delay-SA'].sum() / len(df_sa)\n",
    "median_delay_ML = df_ml['median_delay-ML'].sum() / len(df_ml)\n",
    "print(\"average of median delay SA: \", decimal_to_time(median_delay_SA))\n",
    "print(\"average median delay ML: \", decimal_to_time(median_delay_ML))\n",
    "\n",
    "# calculate average objval for SA and ML\n",
    "objval_SA = df_sa['obj_val-SA'].sum() / len(df_sa)\n",
    "objval_ML = df_ml['obj_val-ML'].sum() / len(df_ml)\n",
    "print(\"average objval SA: \", objval_SA) # i made a mistake in how the objval is saved: the ML saves the objval of the failed solution, while the SA saves the objval of the last valid solution\n",
    "print(\"average objval ML: \", objval_ML)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:17:08.523898200Z",
     "start_time": "2024-01-07T17:17:08.486245100Z"
    }
   },
   "id": "4e79e4712c1732e5",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  389\n",
      "valid solutions ML:  389\n",
      "average and stddev: ( 0.03349071278318259 0.2922943132249796 )\n",
      "median and stddev: ( 0.03245501285347037 0.3447036985515387 )\n"
     ]
    }
   ],
   "source": [
    "df_sa['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-SA'] = df_sa['valid_solution-SA']\n",
    "\n",
    "# now only look at the instances that are solved by both SA and ML\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_sa_solved = df_sa[df_sa['valid_solution-SA'] == 1]\n",
    "\n",
    "df_sa_solved = df_sa_solved[df_sa_solved['valid_solution-ML'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-SA'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa_solved['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml_solved['valid_solution-ML'].sum())\n",
    "\n",
    "avg_diff = df_sa_solved['average_delay-SA'] - df_ml_solved['average_delay-ML']\n",
    "median_diff = df_sa_solved['median_delay-SA'] - df_ml_solved['median_delay-ML']\n",
    "print(\"average and stddev: (\", avg_diff.mean(), avg_diff.std(), \")\")\n",
    "print(\"median and stddev: (\", median_diff.mean(), median_diff.std(), \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:28:27.348838400Z",
     "start_time": "2024-01-08T05:28:27.331722400Z"
    }
   },
   "id": "e91cd8413e2c1680",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# lastly, for the training range\n",
    "df_ml = pd.read_excel('results/SA/ML-Results/ML151-200ex10-040-099-check.xlsx')\n",
    "\n",
    "# load in random data\n",
    "df_sa = pd.read_excel('results/SA/100ex20-SA200/output_100e_200-101to200.xlsx')\n",
    "# only keep the instace 151-200\n",
    "df_sa = df_sa.sort_values(by=['instance'])\n",
    "df_sa = df_sa[1000:2000]\n",
    "# keep half of the data\n",
    "df_sa = df_sa[df_sa.index % 2 == 0]\n",
    "# rename the columns\n",
    "df_sa = df_sa.rename(columns={'median delay': 'median_delay-SA', 'average delay': 'average_delay-SA', 'number of movements': 'movements_reached-SA', 'obj_val': 'obj_val-SA', 't0': 't0-SA', 'alpha': 'alpha-SA', 'valid_solution': 'valid_solution-SA'})\n",
    "\n",
    "\n",
    "# import the instance data\n",
    "df_instances = pd.read_excel('results/instanceData_200.xlsx')\n",
    "df_instances = df_instances[['instance', 'number_of_movements']]\n",
    "# only keep the instace 151-200\n",
    "df_instances = df_instances.sort_values(by=['instance'])\n",
    "df_instances = df_instances[150:200]\n",
    "\n",
    "# merge the instances with the SA&ML data\n",
    "df_ml = pd.merge(df_ml, df_instances, on='instance')\n",
    "df_sa = pd.merge(df_sa, df_instances, on='instance')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:30:19.073693500Z",
     "start_time": "2024-01-08T05:30:18.725473800Z"
    }
   },
   "id": "aede252ba6f1196e",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  393\n",
      "valid solutions ML:  384\n"
     ]
    }
   ],
   "source": [
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml['valid_solution-ML'].sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:30:22.669548300Z",
     "start_time": "2024-01-08T05:30:22.659982500Z"
    }
   },
   "id": "1f882b1f5333f30",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid solutions SA:  365\n",
      "valid solutions ML:  365\n",
      "average and stddev: ( 0.024114946738449217 0.30021876972977135 )\n",
      "median and stddev: ( 0.02203196347031975 0.35134045233134503 )\n"
     ]
    }
   ],
   "source": [
    "df_sa['valid_solution-ML'] = df_ml['valid_solution-ML']\n",
    "df_ml['valid_solution-SA'] = df_sa['valid_solution-SA']\n",
    "\n",
    "# now only look at the instances that are solved by both SA and ML\n",
    "df_ml_solved = df_ml[df_ml['valid_solution-ML'] == 1]\n",
    "df_sa_solved = df_sa[df_sa['valid_solution-SA'] == 1]\n",
    "\n",
    "df_sa_solved = df_sa_solved[df_sa_solved['valid_solution-ML'] == 1]\n",
    "df_ml_solved = df_ml_solved[df_ml_solved['valid_solution-SA'] == 1]\n",
    "\n",
    "# calculate the amount of valid solutions for SA and ML\n",
    "print(\"valid solutions SA: \", df_sa_solved['valid_solution-SA'].sum())\n",
    "print(\"valid solutions ML: \", df_ml_solved['valid_solution-ML'].sum())\n",
    "\n",
    "avg_diff = df_sa_solved['average_delay-SA'] - df_ml_solved['average_delay-ML']\n",
    "median_diff = df_sa_solved['median_delay-SA'] - df_ml_solved['median_delay-ML']\n",
    "print(\"average and stddev: (\", avg_diff.mean(), avg_diff.std(), \")\")\n",
    "print(\"median and stddev: (\", median_diff.mean(), median_diff.std(), \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T05:30:40.139157900Z",
     "start_time": "2024-01-08T05:30:40.108370900Z"
    }
   },
   "id": "47aaeb95693af048",
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
